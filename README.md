# lua-resty-nonblocking-ffi

This library provides an efficient and generic API to do programming in other languages.

**Features:**
* simple but extensible interface
* once and for all, no need to write C/Lua codes to do coupling anymore
* high performance, 3~4 times faster than unix domain socket way
* bridges for python/java, once and for all
* any serialization message format you like

## Background

In openresty land, when you turns to implement some logic, especially to couple with third-party popular frameworks,
it's likely to suck in awkward: make bricks without strawã€‚

1. C is low-level language, very little ecosystem, no unified and rich libraries, and almost
all modern frameworks do not support C, instead, they like Java, Python, Go. For example,
when you need to do grpc to access external services, you must depends on C++ lib, which is huge and cumbersome.

2. Lua is embedded and minority programming language, which means all the powers comes from the host.
In openresty, it means all functionalities comes from lua-nginx-modules. Like C, or even worse, you have to
reinvent the wheels via cosocket to do modern networking stuff. A lot of lua-resty-* born, but they are almost
semi-finished products compared to native lib in other languages. For example, lua-resty-kafka doesn't support
consumer group, lua-resty-postgres doesn't support notify and prepared statements, etc. Moreover, most of those authors
of lua-resty-* stop development at some stage because lua community is so small and less attractive.

To implement a common function in other main stream languages, you have to do a lot of adaptive codes back and forward
between nginx and openresty. For example, http2 requires SNI and viable session reuse, then you have to patch C codes
and openresty and/or nginx. Moreover, when you turn to accomplish a new job, you need to redo all such things again!
Then, a lot of *-nginx-module born and recompile your nginx! Painful, right?

**Why not WASM?**

WASM lacks of below features, which is useless esepcially for openresty:
* no coroutine, which means you need to execute the logic from start to end and block the nginx worker process with arbitrary time
* castrated language support, e.g. go doesn't suppport WASM fully, you need to use tiny-go
* WASI is not supported in almost all lanuages, which means it's hard to use their battery-included lib and ecosystem
* complex development, due to sandbox original intention, you have to export a lot of API for callbacks
* threading model is pending feature and almost all languages do not support it

All in all, WASM is painful and hard way to adapt other languages into the Nginx world.

**May I extend the openresty with modern programming languages and reuse their rich ecosystems directly? That means, we reseved everything from languages and let them work together with Nginx at ease.**

## Architecture

![1663476422225](https://user-images.githubusercontent.com/4401042/190886217-9fb97d6c-bf3f-435d-bdd8-702ce86dde2d.png)

## Concepts

### Library
Shared libraries including your logics.

In Go, it means the output library generated by `go build`.

In Java and Python, it means the bridged shared library and native Java classes/jar and python modules.

### Library configuration
To configure the library, e.g. etcd endpoints, kafka endpoints, etc.

### Runtime
The combination of library and configuration would init a new runtime, which may include some threads or goroutines to do jobs.
You could use the same library with different configuration, which is a common case.

### Request-Response Model

Coupling between nginx worker process and the runtime is based on message exchanges, which contains two directions:

1. **Request**

* the lua coroutine creates a task
* associate the task with request message, which is C `malloc()` char array
* put the task into the thread-safe queue of the runtime and yield
* the runtime polls this queue

Why not call API provided by other languages?
* In Go, due to GMP model, it may block the nginx worker process
* It increases the burden for other languages to provide such API

2. **Response**

The runtime injects the response (also C `malloc()` char array)
into the `ngx_thread_pool_done` queue directly and notify the nginx epoll loop via eventfd,
the nginx would resumes the lua coroutine then.

Thanks to the simple patch of nginx (ten lines of additional codes), here no need to use
traditional nginx worker thread pool for lua to get the response, which is low-efficient (thread context switchs),
and nonscaleable (consumption of linux threads).

## API description

## Build

```bash
# OS: Ubuntu 20.04

apt install -y build-essential

cd /opt
git clone https://github.com/kingluo/lua-resty-nonblocking-ffi
wget https://openresty.org/download/openresty-1.21.4.1.tar.gz
tar zxf openresty-1.21.4.1.tar.gz

# patch and install files
cd /opt/openresty-1.21.4.1/bundle/ngx_lua-0.10.21/
patch -p1 < /opt/lua-resty-nonblocking-ffi/patches/config.patch
cd /opt/openresty-1.21.4.1/bundle/lua-resty-core-0.1.23/lib/resty/
patch -p1 < /opt/lua-resty-nonblocking-ffi/patches/core.lua.patch
cd /opt/openresty-1.21.4.1/bundle/nginx-1.21.4/src/core/
patch -p1 < /opt/lua-resty-nonblocking-ffi/patches/ngx_thread_pool.c.patch

cd /opt/lua-resty-nonblocking-ffi/
cp -a ngx_http_lua_nonblocking_ffi.c ngx_http_lua_nonblocking_ffi.h /opt/openresty-1.21.4.1/bundle/ngx_lua-0.10.21/src/
cp -a nonblocking_ffi.lua /opt/openresty-1.21.4.1/bundle/lua-resty-core-0.1.23/lib/resty/core/

cd /opt/openresty-1.21.4.1

./configure --prefix=/opt/nffi --with-threads
make install
```
